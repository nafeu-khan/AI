{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3da7f00",
   "metadata": {},
   "source": [
    "# Medical Chatbot using Generative AI\n",
    "This notebook recreates the functionality of the [Medical Chatbot project](https://github.com/entbappy/End-to-end-Medical-Chatbot-Generative-AI), allowing PDF input and Generative AI-powered Q&A using LangChain and Pinecone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b358762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install langchain pinecone-client python-dotenv PyPDF2 matplotlib-inline>=0.1 langchain-google-genai google-generativeai pyreadline3 langchain-pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfc5f558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -U  pypdf langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101a3574",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "from pinecone import Pinecone, PodSpec\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "load_dotenv('.env')\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "\n",
    "pc_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "pc_environment = \"us-west1-gcp\"\n",
    "pc = Pinecone(api_key=pc_api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d1f7c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded and split 78 chunks from PDF.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# pdf_path = \"Data/paper.pdf\"\n",
    "# pdf_path = \"Data/MedicalBook2.pdf\"\n",
    "pdf_path = \"Data/derma.pdf\"\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "documents = loader.load()\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "print(f\"Loaded and split {len(texts)} chunks from PDF.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95f7f413",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "index_name = \"medical-chatbot-gemini\"\n",
    "\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=index_name, \n",
    "        dimension=768, \n",
    "        metric='cosine', \n",
    "        spec=PodSpec(environment=pc_environment)\n",
    "    )\n",
    "\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    texts, \n",
    "    embeddings, \n",
    "    index_name=index_name\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "efe3be94",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0, convert_system_message_to_human=True)\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=docsearch.as_retriever()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "603b504f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pyhton_project\\daysOfMl\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:357: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Hairfall is also known as alopecia. The symptoms of alopecia are hair loss, for example, a well-defined patch of complete hair loss. Hair loss can also be caused by premature entry of hair follicles into the telogen phase.\n"
     ]
    }
   ],
   "source": [
    "query = \"What are the symptoms of hairfall?\"\n",
    "response = qa_chain.run(query)\n",
    "print(\"Response:\", response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbca73c1",
   "metadata": {},
   "source": [
    "âœ… You're now able to ask medical questions based on the content of your PDF using a Generative AI-powered chatbot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86dee779",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pyhton_project\\daysOfMl\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:357: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: The writers of the book are Dr. Nicole Yi Zhen Chiang and Professor Julian Verbov.\n"
     ]
    }
   ],
   "source": [
    "query = \"Who are writer of the book?\"\n",
    "response = qa_chain.run(query)\n",
    "print(\"Response:\", response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
